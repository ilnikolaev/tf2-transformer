{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sentencepiece\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2008f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(\"transformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c62ad",
   "metadata": {},
   "source": [
    "Maximum length hyperparameter of pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54951af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537f470",
   "metadata": {},
   "source": [
    "Performing top-k sampling on the probabilities returned by the model.\n",
    "The k argument in tf.math.top_k indicates how many elements with the biggest values should be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_logits(logits):\n",
    "    logits, indices = tf.math.top_k(logits, k=10, sorted=True) \n",
    "    softmax_preds = tf.nn.softmax(tf.expand_dims(logits,0))[0]\n",
    "    return np.random.choice(indices.numpy(), p=softmax_preds.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847bce5e",
   "metadata": {},
   "source": [
    "Pad tokenized sentences to model input size i.e. maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa8998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(sentence):\n",
    "    x = sentence\n",
    "    pad_len = max_len - len(sentence)\n",
    "    sample_index = len(sentence) - 1\n",
    "    if pad_len < 0:\n",
    "        x = sentence[:max_len]\n",
    "        sample_index = max_len - 1\n",
    "    elif pad_len > 0:\n",
    "        x = sentence + [0] * pad_len\n",
    "        \n",
    "    return x, sample_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10476d24",
   "metadata": {},
   "source": [
    "Load pretrained BPE tokenizer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = sentencepiece.SentencePieceProcessor()\n",
    "tokenizer.load(\"bpe_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60395616",
   "metadata": {},
   "source": [
    "The model predicts tokens until the maximum length is reached or until the predicted token is equal to 3. After that the collected tokens are detokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"hello\"\n",
    "tokens_input = tokenizer.tokenize(sentence)\n",
    "tokens_input_pad, _ = pad(tokens_input)\n",
    "number_of_tokens = 0\n",
    "tokens_target = [2] #<s> start sentence token index must be inserted into this list\n",
    "current_token = tokens_target[0]\n",
    "\n",
    "while number_of_tokens < max_len:\n",
    "    if current_token == 3: # if </s> end of sentence token predicted, stop generating\n",
    "        break\n",
    "    tokens_target_pad, index = pad(tokens_target)\n",
    "    y,_ = model.__call__(tf.Variable([tokens_input_pad]), tf.Variable([tokens_target_pad]))\n",
    "    sample_token = sample_from_logits(y[0][index])\n",
    "    tokens_target.append(sample_token)\n",
    "    current_token = sample_token\n",
    "    number_of_tokens += 1\n",
    "    \n",
    "tokens_target = list(map(lambda x: x.item(), tokens_target[1:len(tokens_target)]))\n",
    "tokenizer.detokenize(tokens_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36370388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
